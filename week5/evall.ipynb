{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0327b84-7bf6-4504-9e7c-d6e8640dfc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2491c53d-78d0-4c6a-a23c-a0bcdd83192d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# price is a factor for our company, so we're going to use a low cost model\n",
    "\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "db_name = \"vector_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0eb598e7-1d4b-4176-8c09-7a469919f900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92ad784e-8fb7-4bcc-bd13-31aca8ed7649",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "pdating app_json in apps table: 0it [00:00, ?it/s][00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Imports main tools:\n",
    "from trulens.apps.langchain import TruChain\n",
    "from trulens.core import TruSession\n",
    "\n",
    "session = TruSession()\n",
    "session.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e13f13d-a1a2-424b-a17d-210a8e9b5ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports from LangChain to build app\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f479d91-c849-4b5b-b3b9-27081724109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "758bb765-fcf3-4d29-9be9-91a4f3ff14d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vectorstore = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e1d965c-c1dd-49ad-87a2-d7eb861e7ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages/langsmith/client.py:323: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms.ollama import Ollama\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9dfd55c-04e5-4fc3-8f9a-1431d563983f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task Decomposition is a technique that breaks down complex tasks into smaller and simpler steps to enhance model performance. It involves transforming big tasks into manageable tasks by decomposing them into multiple steps. Task decomposition can be done using simple prompting, task-specific instructions, or with human inputs.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What is Task Decomposition?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "428f92b1-fbc6-4208-8e66-b7a207988854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Groundedness, input source will be set to __record__.app.first.steps__.context.first.invoke.rets[:].page_content.collect() .\n",
      "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input context will be set to __record__.app.first.steps__.context.first.invoke.rets[:].page_content .\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from trulens.core import Feedback\n",
    "from trulens.providers.openai import OpenAI\n",
    "\n",
    "# Initialize provider class\n",
    "provider = OpenAI()\n",
    "\n",
    "# select context to be used in feedback. the location of context is app specific.\n",
    "context = TruChain.select_context(rag_chain)\n",
    "\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(\n",
    "        provider.groundedness_measure_with_cot_reasons, name=\"Groundedness\"\n",
    "    )\n",
    "    .on(context.collect())  # collect context chunks into a list\n",
    "    .on_output()\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_answer_relevance = Feedback(\n",
    "    provider.relevance_with_cot_reasons, name=\"Answer Relevance\"\n",
    ").on_input_output()\n",
    "# Context relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(\n",
    "        provider.context_relevance_with_cot_reasons, name=\"Context Relevance\"\n",
    "    )\n",
    "    .on_input()\n",
    "    .on(context)\n",
    "    .aggregate(np.mean)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa90d462-0c86-475e-a23d-05e21db27487",
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_recorder = TruChain(\n",
    "    rag_chain,\n",
    "    app_name=\"ChatApplication\",\n",
    "    app_version=\"Chain1\",\n",
    "    feedbacks=[f_answer_relevance, f_context_relevance, f_groundedness],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4a7d48a-d6c3-41a2-af65-2c452a63bf77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The text appears to be a collection of research papers and concepts related to Large Language Models (LLMs) and their applications in various domains. Here's a summary of the main points:\\n\\n**Tool-Augmented LLMs**\\n\\n* Tool-augmented LLMs use external tools and APIs to perform specific tasks, such as API calls, search engine queries, or data management.\\n* The workflow involves three levels:\\n\\t1. Decision-making: determining whether an API call is needed and selecting the right API.\\n\\t2. Task execution: executing the task using the selected API and logging results.\\n\\t3. Response generation: summarizing the results for the user.\\n\\n**Challenges**\\n\\n* Efficiency improvement is needed to reduce inference times and interactions with other models.\\n* Stability improvements are required for LLM outputs and external model services.\\n* The context window is limited, which affects in-context learning and long-term memory storage.\\n\\n**API-Bank Benchmark**\\n\\n* A benchmark for evaluating the performance of tool-augmented LLMs.\\n* Contains 53 commonly used API tools, a complete workflow, and 264 annotated dialogues with 568 API calls.\\n\\n**Human Memory Mappings**\\n\\n* Sensory memory corresponds to learning embedding representations for raw inputs (text, image, etc.).\\n* Short-term memory corresponds to in-context learning, limited by the finite context window length of Transformer.\\n* Long-term memory corresponds to an external vector store that can be attended to at query time, accessible via fast retrieval.\\n\\nOverall, the text discusses the potential benefits and challenges of using LLMs with external tools and APIs, as well as the importance of understanding human memory and its mappings to machine learning representations.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages/trulens/feedback/llm_provider.py:1521: UserWarning: Failed to process and remove trivial statements. Proceeding with all statements.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with tru_recorder as recording:\n",
    "    llm_response = rag_chain.invoke(\"What is Task Decomposition?\")\n",
    "\n",
    "display(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "878ece78-e691-4d80-8c97-77a63d0d0f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_name</th>\n",
       "      <th>app_version</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ChatApplication</th>\n",
       "      <th>Chain1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>118.455861</td>\n",
       "      <td>0.002489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Answer Relevance  Context Relevance  \\\n",
       "app_name        app_version                                        \n",
       "ChatApplication Chain1                    1.0           0.416667   \n",
       "\n",
       "                             Groundedness     latency  total_cost  \n",
       "app_name        app_version                                        \n",
       "ChatApplication Chain1                1.0  118.455861    0.002489  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.get_leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5de35b5-d4b0-418e-b83c-7dfd1b8758e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "      <th>reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is Task Decomposition?</td>\n",
       "      <td>Fig. 1. Overview of a LLM-powered autonomous a...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Criteria: The context must be relevant and hel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is Task Decomposition?</td>\n",
       "      <td>Fig. 10. A picture of a sea otter using rock t...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>Criteria: The context must be relevant and hel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is Task Decomposition?</td>\n",
       "      <td>(3) Task execution: Expert models execute on t...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>Criteria: The context must be relevant and hel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is Task Decomposition?</td>\n",
       "      <td>Fig. 6. Illustration of how Algorithm Distilla...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Criteria: The context provided does not addres...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      question  \\\n",
       "0  What is Task Decomposition?   \n",
       "1  What is Task Decomposition?   \n",
       "2  What is Task Decomposition?   \n",
       "3  What is Task Decomposition?   \n",
       "\n",
       "                                             context     score  \\\n",
       "0  Fig. 1. Overview of a LLM-powered autonomous a...  1.000000   \n",
       "1  Fig. 10. A picture of a sea otter using rock t...  0.333333   \n",
       "2  (3) Task execution: Expert models execute on t...  0.333333   \n",
       "3  Fig. 6. Illustration of how Algorithm Distilla...  0.000000   \n",
       "\n",
       "                                              reason  \n",
       "0  Criteria: The context must be relevant and hel...  \n",
       "1  Criteria: The context must be relevant and hel...  \n",
       "2  Criteria: The context must be relevant and hel...  \n",
       "3  Criteria: The context provided does not addres...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trulens.dashboard.display import get_feedback_result\n",
    "\n",
    "last_record = recording.records[-1]\n",
    "get_feedback_result(last_record, \"Context Relevance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84be545a-5506-4bd5-8376-e34e0febeb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ragas\n",
      "  Downloading ragas-0.2.7-py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: numpy in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from ragas) (1.26.4)\n",
      "Requirement already satisfied: datasets in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from ragas) (3.0.2)\n",
      "Requirement already satisfied: tiktoken in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from ragas) (0.8.0)\n",
      "Requirement already satisfied: langchain in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from ragas) (0.3.10)\n",
      "Requirement already satisfied: langchain-core in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from ragas) (0.3.22)\n",
      "Requirement already satisfied: langchain-community in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from ragas) (0.3.10)\n",
      "Requirement already satisfied: langchain_openai in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from ragas) (0.2.11)\n",
      "Requirement already satisfied: nest-asyncio in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from ragas) (1.6.0)\n",
      "Collecting appdirs (from ragas)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: pydantic>=2 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from ragas) (2.10.3)\n",
      "Requirement already satisfied: openai>1 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from ragas) (1.57.0)\n",
      "Collecting pysbd>=0.3.4 (from ragas)\n",
      "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from openai>1->ragas) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from openai>1->ragas) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from openai>1->ragas) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from openai>1->ragas) (0.6.1)\n",
      "Requirement already satisfied: sniffio in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from openai>1->ragas) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from openai>1->ragas) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from openai>1->ragas) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from pydantic>=2->ragas) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from pydantic>=2->ragas) (2.27.1)\n",
      "Requirement already satisfied: filelock in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from datasets->ragas) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from datasets->ragas) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from datasets->ragas) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from datasets->ragas) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from datasets->ragas) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from datasets->ragas) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from datasets->ragas) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->ragas) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from datasets->ragas) (3.10.10)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from datasets->ragas) (0.26.1)\n",
      "Requirement already satisfied: packaging in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from datasets->ragas) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from datasets->ragas) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain->ragas) (2.0.36)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain->ragas) (0.3.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain->ragas) (0.1.129)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain->ragas) (8.4.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-core->ragas) (1.33)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-community->ragas) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-community->ragas) (0.4.0)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-community->ragas) (2.6.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from tiktoken->ragas) (2024.9.11)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from aiohttp->datasets->ragas) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from aiohttp->datasets->ragas) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from aiohttp->datasets->ragas) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from aiohttp->datasets->ragas) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from aiohttp->datasets->ragas) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from aiohttp->datasets->ragas) (1.16.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai>1->ragas) (3.10)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (3.23.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (0.9.0)\n",
      "Requirement already satisfied: certifi in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>1->ragas) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>1->ragas) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>1->ragas) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core->ragas) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->ragas) (3.10.10)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->ragas) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from requests>=2.32.2->datasets->ragas) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from requests>=2.32.2->datasets->ragas) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain->ragas) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from pandas->datasets->ragas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from pandas->datasets->ragas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from pandas->datasets->ragas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas) (1.16.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (1.0.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/yasar/anaconda3/envs/llms/lib/python3.11/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets->ragas) (0.2.0)\n",
      "Downloading ragas-0.2.7-py3-none-any.whl (163 kB)\n",
      "Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: appdirs, pysbd, ragas\n",
      "Successfully installed appdirs-1.4.4 pysbd-0.3.4 ragas-0.2.7\n"
     ]
    }
   ],
   "source": [
    "!pip install ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b44619a-fb5b-462a-a481-72f5e46cd030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.dataset_schema import SingleTurnSample\n",
    "from ragas.metrics import NonLLMContextRecall\n",
    "\n",
    "sample = SingleTurnSample(\n",
    "    retrieved_contexts=[\"Paris is the capital of France.\"], \n",
    "    reference_contexts=[\"Paris is the capital of France.\", \"The Eiffel Tower is one of the most famous landmarks in Paris.\"]\n",
    ")\n",
    "\n",
    "context_recall = NonLLMContextRecall()\n",
    "await context_recall.single_turn_ascore(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51c2fe57-6d7c-4afb-acba-19495af192b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rapidfuzz\n",
      "  Downloading rapidfuzz-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Downloading rapidfuzz-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mMB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "Installing collected packages: rapidfuzz\n",
      "Successfully installed rapidfuzz-3.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install rapidfuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295216d8-2f5e-4bf9-9977-0ffdb08e89af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
